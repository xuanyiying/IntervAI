/**
 * Chat Intent Service
 * Handles intent recognition and dispatches to appropriate handlers
 */

import {
  Injectable,
  Logger,
  Inject,
  forwardRef,
  OnModuleInit,
  Optional,
} from '@nestjs/common';
import { PrismaService } from '@/prisma/prisma.service';
import { AIEngineService } from '@/ai-providers/ai-engine.service';
import { ResumeOptimizerService } from '@/resume/services/resume-optimizer.service';
import { AIRequest } from '@/ai-providers/interfaces';
import { PromptScenario } from '@/ai-providers/interfaces/prompt-template.interface';
import { ChatResponse } from './chat.gateway';
import {
  SceneAnalysisService,
  SceneContext,
  SceneAnalysisResult,
} from './scene-analysis.service';
import {
  TeamTaskService,
  ComplexTaskType,
  ComplexTaskResult,
} from '@/agent/team/team-task.service';

export enum ChatIntent {
  OPTIMIZE_RESUME = 'optimize_resume',
  PARSE_RESUME = 'parse_resume',
  MOCK_INTERVIEW = 'mock_interview',
  INTERVIEW_PREDICTION = 'interview_prediction',
  PARSE_JOB_DESCRIPTION = 'parse_job_description',
  CAREER_ADVICE = 'career_advice',
  SKILL_ANALYSIS = 'skill_analysis',
  SALARY_NEGOTIATION = 'salary_negotiation',
  FULL_OPTIMIZATION = 'full_optimization',
  INTERVIEW_PREPARATION = 'interview_preparation',
  CAREER_TRANSITION = 'career_transition',
  COMPETITIVE_ANALYSIS = 'competitive_analysis',
  GENERAL_CHAT = 'general_chat',
  HELP = 'help',
  UNKNOWN = 'unknown',
}

interface IntentResult {
  intent: ChatIntent;
  confidence: number;
  entities?: Record<string, any>;
  reasoning?: string;
  suggestedActions?: string[];
}

// In-memory cache for user's resume content (should use Redis in production)
const userResumeCache = new Map<
  string,
  { resumeId: string; content: string; timestamp: number }
>();

@Injectable()
export class ChatIntentService implements OnModuleInit {
  private readonly logger = new Logger(ChatIntentService.name);
  private useAISceneAnalysis: boolean = true;
  private useTeamAgents: boolean = true;

  private readonly intentKeywords: Record<ChatIntent, string[]> = {
    [ChatIntent.OPTIMIZE_RESUME]: [
      'ä¼˜åŒ–',
      'æ”¹è¿›',
      'æ¶¦è‰²',
      'æå‡',
      'ä¿®æ”¹',
      'æ”¹å–„',
      'å®Œå–„',
      'optimize',
      'improve',
      'enhance',
      'polish',
      'refine',
      'ä¼˜åŒ–ç®€å†',
      'æ”¹è¿›ç®€å†',
      'æ¶¦è‰²ç®€å†',
      'ç®€å†ä¼˜åŒ–',
    ],
    [ChatIntent.MOCK_INTERVIEW]: [
      'æ¨¡æ‹Ÿé¢è¯•',
      'é¢è¯•',
      'ç»ƒä¹ ',
      'mock',
      'interview',
      'practice',
      'æ¨¡æ‹Ÿ',
      'é¢è¯•è§£å¿§',
    ],
    [ChatIntent.INTERVIEW_PREDICTION]: [
      'é¢è¯•é¢„æµ‹',
      'é¢„æµ‹',
      'é¢˜ç›®',
      'è€ƒé¢˜',
      'prediction',
      'predict',
      'questions',
    ],
    [ChatIntent.PARSE_JOB_DESCRIPTION]: [
      'èŒä½è¾“å…¥',
      'è¾“å…¥èŒä½',
      'è§£æèŒä½',
      'JD',
      'èŒä½',
      'èŒä½æè¿°',
      'job',
      'description',
    ],
    [ChatIntent.PARSE_RESUME]: [
      'è§£æ',
      'åˆ†æ',
      'æŸ¥çœ‹',
      'è¯»å–',
      'parse',
      'analyze',
      'read',
      'extract',
    ],
    [ChatIntent.CAREER_ADVICE]: [
      'èŒä¸šå»ºè®®',
      'èŒä¸šè§„åˆ’',
      'æ±‚èŒå»ºè®®',
      'èŒä¸šå‘å±•',
      'career',
      'advice',
      'planning',
    ],
    [ChatIntent.SKILL_ANALYSIS]: [
      'æŠ€èƒ½åˆ†æ',
      'æŠ€èƒ½è¯„ä¼°',
      'èƒ½åŠ›åˆ†æ',
      'skill',
      'analysis',
      'assessment',
    ],
    [ChatIntent.SALARY_NEGOTIATION]: [
      'è–ªèµ„è°ˆåˆ¤',
      'è–ªèµ„',
      'å·¥èµ„',
      'è–ªé…¬',
      'salary',
      'negotiation',
      'compensation',
    ],
    [ChatIntent.FULL_OPTIMIZATION]: [
      'å®Œæ•´ä¼˜åŒ–',
      'æ·±åº¦ä¼˜åŒ–',
      'å…¨é¢ä¼˜åŒ–',
      'æ ¹æ®JDä¼˜åŒ–',
      'é’ˆå¯¹èŒä½ä¼˜åŒ–',
      'full optimization',
    ],
    [ChatIntent.INTERVIEW_PREPARATION]: [
      'é¢è¯•å‡†å¤‡',
      'å‡†å¤‡é¢è¯•',
      'é¢è¯•æ”»ç•¥',
      'é¢è¯•æŠ€å·§',
      'interview preparation',
    ],
    [ChatIntent.CAREER_TRANSITION]: [
      'èŒä¸šè½¬å‹',
      'è½¬è¡Œ',
      'èŒä¸šè½¬æ¢',
      'career transition',
      'switch career',
    ],
    [ChatIntent.COMPETITIVE_ANALYSIS]: [
      'ç«äº‰åŠ›åˆ†æ',
      'ç«äº‰åˆ†æ',
      'ä¼˜åŠ£åŠ¿åˆ†æ',
      'competitive analysis',
      'strength weakness',
    ],
    [ChatIntent.HELP]: [
      'å¸®åŠ©',
      'æ€ä¹ˆç”¨',
      'å¦‚ä½•',
      'ä½¿ç”¨è¯´æ˜',
      'åŠŸèƒ½',
      'help',
      'how to',
      'guide',
      'tutorial',
    ],
    [ChatIntent.GENERAL_CHAT]: [],
    [ChatIntent.UNKNOWN]: [],
  };

  constructor(
    private readonly prisma: PrismaService,
    private readonly aiEngineService: AIEngineService,
    private readonly sceneAnalysisService: SceneAnalysisService,
    @Inject(forwardRef(() => ResumeOptimizerService))
    private readonly resumeOptimizerService: ResumeOptimizerService,
    @Optional() private readonly teamTaskService: TeamTaskService
  ) {}

  async onModuleInit(): Promise<void> {
    this.logger.log(
      'ChatIntentService initialized with AI scene analysis enabled'
    );
    if (this.teamTaskService?.isEnabled()) {
      this.logger.log('Team Agent integration enabled');
    }
  }

  /**
   * Store user's resume content for later use
   */
  async storeUserResumeContent(
    userId: string,
    resumeId: string,
    content: string
  ): Promise<void> {
    userResumeCache.set(userId, {
      resumeId,
      content,
      timestamp: Date.now(),
    });
    this.logger.debug(
      `Stored resume content for user ${userId}, resumeId: ${resumeId}`
    );
  }

  /**
   * Get user's latest resume content
   */
  async getUserResumeContent(
    userId: string
  ): Promise<{ resumeId: string; content: string } | null> {
    // First check cache
    const cached = userResumeCache.get(userId);
    if (cached && Date.now() - cached.timestamp < 3600000) {
      // 1 hour cache
      this.logger.debug(
        `Using cached resume for user ${userId}, content length: ${cached.content.length}`
      );
      return { resumeId: cached.resumeId, content: cached.content };
    }

    // Fallback to database - get user's latest parsed resume
    const resume = await this.prisma.resume.findFirst({
      where: {
        userId,
        parseStatus: 'COMPLETED',
      },
      orderBy: { updatedAt: 'desc' },
    });

    if (resume?.parsedData) {
      const content = this.convertParsedDataToMarkdown(
        resume.parsedData as any
      );

      if (!content || content.trim().length === 0) {
        this.logger.warn(
          `Converted resume content is empty for user ${userId}, resumeId: ${resume.id}`
        );
        this.logger.debug(
          `ParsedData structure: ${JSON.stringify(resume.parsedData).substring(0, 200)}`
        );
        return null;
      }

      this.logger.debug(
        `Converted resume to markdown for user ${userId}, content length: ${content.length}`
      );

      userResumeCache.set(userId, {
        resumeId: resume.id,
        content,
        timestamp: Date.now(),
      });
      return { resumeId: resume.id, content };
    }

    this.logger.warn(`No parsed resume found for user ${userId}`);
    return null;
  }

  /**
   * Process incoming message and dispatch to appropriate handler
   */
  async processMessage(
    userId: string,
    conversationId: string,
    content: string,
    metadata: Record<string, any> | undefined,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    try {
      const resumeData = await this.getUserResumeContent(userId);

      const sceneContext: SceneContext = {
        userId,
        conversationId,
        previousMessages: metadata?.previousMessages || [],
        userMetadata: metadata?.userMetadata,
        hasResume: !!resumeData,
        hasJobDescription: !!metadata?.hasJobDescription,
      };

      let intentResult: IntentResult;

      if (this.useAISceneAnalysis) {
        try {
          const sceneResult = await this.sceneAnalysisService.analyzeScene(
            content,
            sceneContext
          );
          intentResult = this.convertSceneResultToIntent(sceneResult);
          this.logger.debug(
            `AI scene analysis: ${intentResult.intent} (confidence: ${intentResult.confidence}, reasoning: ${intentResult.reasoning})`
          );
        } catch (error) {
          this.logger.warn(
            `AI scene analysis failed, falling back to keyword matching: ${error instanceof Error ? error.message : String(error)}`
          );
          intentResult = this.recognizeIntent(content);
        }
      } else {
        intentResult = this.recognizeIntent(content);
        this.logger.debug(
          `Keyword-based intent: ${intentResult.intent} (confidence: ${intentResult.confidence})`
        );
      }

      switch (intentResult.intent) {
        case ChatIntent.OPTIMIZE_RESUME:
          await this.handleOptimizeResume(
            userId,
            conversationId,
            content,
            onChunk,
            onComplete
          );
          break;

        case ChatIntent.MOCK_INTERVIEW:
          await this.handleMockInterview(
            userId,
            conversationId,
            content,
            onChunk,
            onComplete
          );
          break;

        case ChatIntent.INTERVIEW_PREDICTION:
          await this.handleInterviewPrediction(
            userId,
            conversationId,
            content,
            onChunk,
            onComplete
          );
          break;

        case ChatIntent.PARSE_JOB_DESCRIPTION:
          await this.handleParseJobDescription(
            userId,
            conversationId,
            content,
            onChunk,
            onComplete
          );
          break;

        case ChatIntent.CAREER_ADVICE:
          await this.handleCareerAdvice(userId, content, onChunk, onComplete);
          break;

        case ChatIntent.SKILL_ANALYSIS:
          await this.handleSkillAnalysis(userId, content, onChunk, onComplete);
          break;

        case ChatIntent.SALARY_NEGOTIATION:
          await this.handleSalaryNegotiation(
            userId,
            content,
            onChunk,
            onComplete
          );
          break;

        case ChatIntent.FULL_OPTIMIZATION:
          await this.handleFullOptimization(
            userId,
            content,
            metadata,
            onChunk,
            onComplete
          );
          break;

        case ChatIntent.INTERVIEW_PREPARATION:
          await this.handleInterviewPreparation(
            userId,
            content,
            metadata,
            onChunk,
            onComplete
          );
          break;

        case ChatIntent.CAREER_TRANSITION:
          await this.handleCareerTransition(
            userId,
            content,
            metadata,
            onChunk,
            onComplete
          );
          break;

        case ChatIntent.COMPETITIVE_ANALYSIS:
          await this.handleCompetitiveAnalysis(
            userId,
            content,
            metadata,
            onChunk,
            onComplete
          );
          break;

        case ChatIntent.HELP:
          await this.handleHelp(onChunk, onComplete);
          break;

        case ChatIntent.GENERAL_CHAT:
        default:
          await this.handleGeneralChat(userId, content, onChunk, onComplete);
          break;
      }
    } catch (error) {
      this.logger.error(
        `Intent processing failed: ${error instanceof Error ? error.message : String(error)}`
      );
      const errorMessage =
        error instanceof Error
          ? error.message
          : 'å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚';
      await onComplete(errorMessage, { error: true });
    }
  }

  private convertSceneResultToIntent(
    sceneResult: SceneAnalysisResult
  ): IntentResult {
    const sceneToIntentMap: Record<string, ChatIntent> = {
      optimize_resume: ChatIntent.OPTIMIZE_RESUME,
      parse_resume: ChatIntent.PARSE_RESUME,
      mock_interview: ChatIntent.MOCK_INTERVIEW,
      interview_prediction: ChatIntent.INTERVIEW_PREDICTION,
      parse_job_description: ChatIntent.PARSE_JOB_DESCRIPTION,
      career_advice: ChatIntent.CAREER_ADVICE,
      skill_analysis: ChatIntent.SKILL_ANALYSIS,
      salary_negotiation: ChatIntent.SALARY_NEGOTIATION,
      full_optimization: ChatIntent.FULL_OPTIMIZATION,
      interview_preparation: ChatIntent.INTERVIEW_PREPARATION,
      career_transition: ChatIntent.CAREER_TRANSITION,
      competitive_analysis: ChatIntent.COMPETITIVE_ANALYSIS,
      general_chat: ChatIntent.GENERAL_CHAT,
      help: ChatIntent.HELP,
      unknown: ChatIntent.UNKNOWN,
    };

    return {
      intent: sceneToIntentMap[sceneResult.scene] || ChatIntent.GENERAL_CHAT,
      confidence: sceneResult.confidence,
      entities: sceneResult.entities,
      reasoning: sceneResult.reasoning,
      suggestedActions: sceneResult.suggestedActions,
    };
  }

  /**
   * Recognize user intent from message content
   */
  private recognizeIntent(content: string): IntentResult {
    const lowerContent = content.toLowerCase();

    // Check each intent's keywords
    for (const [intent, keywords] of Object.entries(this.intentKeywords)) {
      if (keywords.length === 0) continue;

      for (const keyword of keywords) {
        if (lowerContent.includes(keyword.toLowerCase())) {
          return {
            intent: intent as ChatIntent,
            confidence: 0.9,
          };
        }
      }
    }

    // Default to general chat
    return {
      intent: ChatIntent.GENERAL_CHAT,
      confidence: 0.5,
    };
  }

  /**
   * Handle resume optimization request
   */
  private async handleOptimizeResume(
    userId: string,
    conversationId: string,
    userMessage: string,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    // Get user's resume content
    const resumeData = await this.getUserResumeContent(userId);

    if (!resumeData) {
      await onComplete(
        'è¯·å…ˆä¸Šä¼ æ‚¨çš„ç®€å†æ–‡ä»¶ï¼Œæˆ‘æ‰èƒ½å¸®æ‚¨ä¼˜åŒ–ç®€å†å†…å®¹ã€‚æ‚¨å¯ä»¥ç‚¹å‡»ä¸Šä¼ æŒ‰é’®æˆ–ç›´æ¥æ‹–æ‹½æ–‡ä»¶åˆ°èŠå¤©çª—å£ã€‚',
        { action: 'request_upload' }
      );
      return;
    }

    // Validate resume content
    if (!resumeData.content || resumeData.content.trim().length === 0) {
      this.logger.error(
        `Resume content is empty for user ${userId}, resumeId: ${resumeData.resumeId}`
      );
      await onComplete(
        'ç®€å†å†…å®¹ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œä¼˜åŒ–ã€‚è¯·é‡æ–°ä¸Šä¼ ç®€å†æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚',
        { error: true, action: 'content_empty' }
      );
      return;
    }

    this.logger.log(
      `Starting resume optimization for user ${userId}, content length: ${resumeData.content.length}`
    );

    // Send initial message
    onChunk({
      type: 'chunk',
      content: 'æ”¶åˆ°ï¼æ­£åœ¨ä¸ºæ‚¨ä¼˜åŒ–ç®€å†å†…å®¹...\n\n',
      timestamp: Date.now(),
    });

    // Stream optimization
    let fullContent = '';

    try {
      const stream = this.resumeOptimizerService.optimizeResume(
        resumeData.content,
        userId,
        { language: 'zh-CN' }
      );

      for await (const chunk of stream) {
        if (chunk.type === 'chunk' && chunk.content) {
          fullContent += chunk.content;
          onChunk({
            type: 'chunk',
            content: chunk.content,
            timestamp: Date.now(),
          });
        } else if (chunk.type === 'error') {
          throw new Error(chunk.message || 'Optimization failed');
        }
      }

      // Add completion tips
      const tips = this.generateOptimizationTips(fullContent);
      const finalContent = fullContent + tips;

      this.logger.log(
        `Resume optimization completed for user ${userId}, output length: ${fullContent.length}`
      );

      await onComplete(finalContent, {
        type: 'optimization_result',
        resumeId: resumeData.resumeId,
        optimizedContent: fullContent,
      });
    } catch (error) {
      this.logger.error(
        `Resume optimization failed: ${error instanceof Error ? error.message : String(error)}`
      );
      await onComplete(
        `ç®€å†ä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}ã€‚è¯·ç¨åé‡è¯•ã€‚`,
        { error: true }
      );
    }
  }

  /**
   * Handle mock interview request
   */
  private async handleMockInterview(
    userId: string,
    conversationId: string,
    userMessage: string,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    const resumeData = await this.getUserResumeContent(userId);

    let systemPrompt =
      'ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„é¢è¯•å®˜ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„ç®€å†å†…å®¹ï¼Œä¸ºç”¨æˆ·è¿›è¡Œä¸€æ¬¡æ¨¡æ‹Ÿé¢è¯•ã€‚ä½ å¯ä»¥å…ˆæå‡ºä¸€ä¸ªé¢è¯•é—®é¢˜ï¼Œç„¶åæ ¹æ®ç”¨æˆ·çš„å›ç­”è¿›è¡Œè¿½é—®æˆ–ç‚¹è¯„ã€‚';

    if (resumeData) {
      systemPrompt += `\n\nç”¨æˆ·çš„ç®€å†å†…å®¹å¦‚ä¸‹ï¼š\n${resumeData.content}`;
    } else {
      systemPrompt +=
        '\n\nç”¨æˆ·å°šæœªä¸Šä¼ ç®€å†ã€‚ä½ å¯ä»¥å…ˆå»ºè®®ç”¨æˆ·ä¸Šä¼ ç®€å†ï¼Œæˆ–è€…å…ˆè¿›è¡Œä¸€äº›é€šç”¨çš„é¢è¯•å‡†å¤‡é—®é¢˜ã€‚';
    }

    onChunk({
      type: 'chunk',
      content: 'å‡†å¤‡å¥½äº†ï¼è®©æˆ‘ä»¬å¼€å§‹æ¨¡æ‹Ÿé¢è¯•å§ã€‚\n\n',
      timestamp: Date.now(),
    });

    await this.streamAIResponse(
      userId,
      systemPrompt,
      userMessage,
      onChunk,
      async (finalContent) => {
        await onComplete(finalContent, { type: 'mock_interview' });
      }
    );
  }

  /**
   * Handle interview prediction request
   */
  private async handleInterviewPrediction(
    userId: string,
    conversationId: string,
    userMessage: string,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    const resumeData = await this.getUserResumeContent(userId);

    let systemPrompt =
      'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„èŒä¸šé¡¾é—®å’Œé¢è¯•ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„ç®€å†å†…å®¹ï¼Œé¢„æµ‹é¢è¯•ä¸­å¯èƒ½å‡ºç°çš„é—®é¢˜ï¼Œå¹¶æä¾›ç›¸åº”çš„å›ç­”å»ºè®®å’Œæ ¸å¿ƒè€ƒç‚¹åˆ†æã€‚';

    if (resumeData) {
      systemPrompt += `\n\nç”¨æˆ·çš„ç®€å†å†…å®¹å¦‚ä¸‹ï¼š\n${resumeData.content}`;
    } else {
      systemPrompt +=
        '\n\nç”¨æˆ·å°šæœªä¸Šä¼ ç®€å†ã€‚ä½ å¯ä»¥å…ˆæä¾›ä¸€äº›å¸¸è§çš„é€šç”¨é¢è¯•é—®é¢˜é¢„æµ‹ï¼Œå¹¶å»ºè®®ç”¨æˆ·ä¸Šä¼ ç®€å†ä»¥è·å–æ›´ç²¾å‡†çš„é¢„æµ‹ã€‚';
    }

    onChunk({
      type: 'chunk',
      content: 'æ­£åœ¨ä¸ºæ‚¨åˆ†æç®€å†å¹¶é¢„æµ‹é¢è¯•é—®é¢˜...\n\n',
      timestamp: Date.now(),
    });

    await this.streamAIResponse(
      userId,
      systemPrompt,
      userMessage,
      onChunk,
      async (finalContent) => {
        await onComplete(finalContent, { type: 'interview_prediction' });
      }
    );
  }

  /**
   * Handle job description parsing request
   */
  private async handleParseJobDescription(
    userId: string,
    conversationId: string,
    userMessage: string,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    const systemPrompt =
      'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„èŒä½åˆ†æä¸“å®¶ã€‚è¯·å¸®ç”¨æˆ·è§£æèŒä½æè¿°ï¼ˆJDï¼‰ï¼Œæå–å‡ºæ ¸å¿ƒèŒè´£ã€æŠ€èƒ½è¦æ±‚ã€ä»»èŒèµ„æ ¼ç­‰å…³é”®ä¿¡æ¯ï¼Œå¹¶ç»™å‡ºç®€å†æŠ•é€’çš„å»ºè®®ã€‚';

    onChunk({
      type: 'chunk',
      content: 'å¥½çš„ï¼Œè¯·æä¾›èŒä½æè¿°ä¿¡æ¯ï¼Œæˆ‘å°†ä¸ºæ‚¨è¿›è¡Œæ·±åº¦è§£æã€‚\n\n',
      timestamp: Date.now(),
    });

    await this.streamAIResponse(
      userId,
      systemPrompt,
      userMessage,
      onChunk,
      async (finalContent) => {
        await onComplete(finalContent, { type: 'parse_job_description' });
      }
    );
  }

  private async handleCareerAdvice(
    userId: string,
    content: string,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    const resumeData = await this.getUserResumeContent(userId);

    let systemPrompt =
      'ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„èŒä¸šå‘å±•é¡¾é—®ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„èƒŒæ™¯å’Œéœ€æ±‚ï¼Œæä¾›ä¸“ä¸šçš„èŒä¸šè§„åˆ’å»ºè®®ã€è¡Œä¸šå‘å±•è¶‹åŠ¿åˆ†æã€èŒä¸šè½¬å‹æŒ‡å¯¼ç­‰ã€‚';

    if (resumeData) {
      systemPrompt += `\n\nç”¨æˆ·çš„ç®€å†å†…å®¹æ‘˜è¦ï¼š\n${resumeData.content.substring(0, 800)}...`;
    }

    onChunk({
      type: 'chunk',
      content: 'è®©æˆ‘æ¥ä¸ºæ‚¨æä¾›èŒä¸šå‘å±•å»ºè®®...\n\n',
      timestamp: Date.now(),
    });

    await this.streamAIResponse(
      userId,
      systemPrompt,
      content,
      onChunk,
      async (finalContent) => {
        await onComplete(finalContent, { type: 'career_advice' });
      }
    );
  }

  private async handleSkillAnalysis(
    userId: string,
    content: string,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    const resumeData = await this.getUserResumeContent(userId);

    let systemPrompt =
      'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€èƒ½è¯„ä¼°ä¸“å®¶ã€‚è¯·åˆ†æç”¨æˆ·çš„æŠ€èƒ½ç»„åˆï¼Œè¯†åˆ«ä¼˜åŠ¿å’Œå¾…æå‡é¢†åŸŸï¼Œå¹¶æä¾›é’ˆå¯¹æ€§çš„æŠ€èƒ½å‘å±•å»ºè®®ã€‚';

    if (resumeData) {
      systemPrompt += `\n\nç”¨æˆ·çš„ç®€å†å†…å®¹ï¼š\n${resumeData.content}`;
    } else {
      systemPrompt +=
        '\n\nç”¨æˆ·å°šæœªä¸Šä¼ ç®€å†ã€‚è¯·å»ºè®®ç”¨æˆ·ä¸Šä¼ ç®€å†ä»¥è·å–æ›´ç²¾å‡†çš„æŠ€èƒ½åˆ†æã€‚';
    }

    onChunk({
      type: 'chunk',
      content: 'æ­£åœ¨åˆ†ææ‚¨çš„æŠ€èƒ½ç»„åˆ...\n\n',
      timestamp: Date.now(),
    });

    await this.streamAIResponse(
      userId,
      systemPrompt,
      content,
      onChunk,
      async (finalContent) => {
        await onComplete(finalContent, { type: 'skill_analysis' });
      }
    );
  }

  private async handleSalaryNegotiation(
    userId: string,
    content: string,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    const resumeData = await this.getUserResumeContent(userId);

    let systemPrompt =
      'ä½ æ˜¯ä¸€ä¸ªè–ªèµ„è°ˆåˆ¤ä¸“å®¶ã€‚è¯·å¸®åŠ©ç”¨æˆ·äº†è§£å¸‚åœºè–ªèµ„æ°´å¹³ï¼Œåˆ¶å®šè–ªèµ„è°ˆåˆ¤ç­–ç•¥ï¼Œå‡†å¤‡è°ˆåˆ¤è¯æœ¯ï¼Œå¹¶æä¾›åº”å¯¹ä¸åŒæƒ…å†µçš„å»ºè®®ã€‚';

    if (resumeData) {
      systemPrompt += `\n\nç”¨æˆ·çš„ç®€å†å†…å®¹æ‘˜è¦ï¼š\n${resumeData.content.substring(0, 500)}...`;
    }

    onChunk({
      type: 'chunk',
      content: 'è®©æˆ‘æ¥å¸®æ‚¨å‡†å¤‡è–ªèµ„è°ˆåˆ¤...\n\n',
      timestamp: Date.now(),
    });

    await this.streamAIResponse(
      userId,
      systemPrompt,
      content,
      onChunk,
      async (finalContent) => {
        await onComplete(finalContent, { type: 'salary_negotiation' });
      }
    );
  }

  private async handleFullOptimization(
    userId: string,
    content: string,
    metadata: Record<string, any> | undefined,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    onChunk({
      type: 'chunk',
      content: 'æ­£åœ¨å¯åŠ¨å¤šæ™ºèƒ½ä½“å›¢é˜Ÿè¿›è¡Œæ·±åº¦ç®€å†ä¼˜åŒ–...\n\n',
      timestamp: Date.now(),
    });

    if (this.useTeamAgents && this.teamTaskService?.isEnabled()) {
      try {
        const resumeData = await this.getUserResumeContent(userId);
        const jd = metadata?.jobDescription || metadata?.jd;

        if (!resumeData) {
          onChunk({
            type: 'chunk',
            content: 'âš ï¸ è¯·å…ˆä¸Šä¼ æ‚¨çš„ç®€å†ï¼Œä»¥ä¾¿è¿›è¡Œæ·±åº¦ä¼˜åŒ–åˆ†æã€‚\n\n',
            timestamp: Date.now(),
          });
          await onComplete('è¯·å…ˆä¸Šä¼ ç®€å†åå†è¿›è¡Œæ·±åº¦ä¼˜åŒ–ã€‚', {
            type: 'full_optimization',
            requiresResume: true,
          });
          return;
        }

        if (!jd) {
          onChunk({
            type: 'chunk',
            content: 'âš ï¸ è¯·æä¾›ç›®æ ‡èŒä½æè¿°ï¼ˆJDï¼‰ï¼Œä»¥ä¾¿è¿›è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–ã€‚\n\n',
            timestamp: Date.now(),
          });
          await onComplete('è¯·æä¾›èŒä½æè¿°åå†è¿›è¡Œæ·±åº¦ä¼˜åŒ–ã€‚', {
            type: 'full_optimization',
            requiresJD: true,
          });
          return;
        }

        onChunk({
          type: 'chunk',
          content: 'ğŸ“‹ æ­£åœ¨åˆ†ææ‚¨çš„ç®€å†...\n',
          timestamp: Date.now(),
        });

        const result = await this.teamTaskService.executeFullResumeOptimization(
          {
            userId,
            taskType: ComplexTaskType.FULL_RESUME_OPTIMIZATION,
            resumeContent: resumeData.content,
            jobDescription: jd,
          }
        );

        if (result.success && result.data) {
          onChunk({
            type: 'chunk',
            content: '\nâœ… æ·±åº¦ä¼˜åŒ–åˆ†æå®Œæˆï¼\n\n',
            timestamp: Date.now(),
          });

          const output = this.formatTeamResult(result.data);
          await onComplete(output, {
            type: 'full_optimization',
            teamExecutionTime: result.executionTimeMs,
          });
        } else {
          await onComplete(
            `ä¼˜åŒ–è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼š${result.error || 'æœªçŸ¥é”™è¯¯'}ï¼Œè¯·ç¨åé‡è¯•ã€‚`,
            {
              type: 'full_optimization',
              error: true,
            }
          );
        }
      } catch (error) {
        this.logger.error(
          `Full optimization failed: ${error instanceof Error ? error.message : String(error)}`
        );
        await onComplete(`æ·±åº¦ä¼˜åŒ–å¤±è´¥ï¼Œæ­£åœ¨åˆ‡æ¢åˆ°æ ‡å‡†æ¨¡å¼...\n\n`, {
          type: 'full_optimization',
          fallback: true,
        });
      }
    } else {
      onChunk({
        type: 'chunk',
        content: 'å¤šæ™ºèƒ½ä½“å›¢é˜Ÿæš‚ä¸å¯ç”¨ï¼Œæ­£åœ¨ä½¿ç”¨æ ‡å‡†ä¼˜åŒ–æ¨¡å¼...\n\n',
        timestamp: Date.now(),
      });
      await this.handleOptimizeResume(userId, '', content, onChunk, onComplete);
    }
  }

  private async handleInterviewPreparation(
    userId: string,
    content: string,
    metadata: Record<string, any> | undefined,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    onChunk({
      type: 'chunk',
      content: 'æ­£åœ¨å¯åŠ¨å¤šæ™ºèƒ½ä½“å›¢é˜Ÿè¿›è¡Œé¢è¯•å‡†å¤‡åˆ†æ...\n\n',
      timestamp: Date.now(),
    });

    if (this.useTeamAgents && this.teamTaskService?.isEnabled()) {
      try {
        const resumeData = await this.getUserResumeContent(userId);
        const jd = metadata?.jobDescription || metadata?.jd;

        onChunk({
          type: 'chunk',
          content: 'ğŸ¯ æ­£åœ¨åˆ†ææ‚¨çš„èƒŒæ™¯å’Œç›®æ ‡èŒä½...\n',
          timestamp: Date.now(),
        });

        const result = await this.teamTaskService.executeInterviewPreparation({
          userId,
          taskType: ComplexTaskType.INTERVIEW_PREPARATION,
          resumeContent: resumeData?.content,
          jobDescription: jd,
          additionalContext: metadata,
        });

        if (result.success && result.data) {
          onChunk({
            type: 'chunk',
            content: '\nâœ… é¢è¯•å‡†å¤‡åˆ†æå®Œæˆï¼\n\n',
            timestamp: Date.now(),
          });

          const output = this.formatTeamResult(result.data);
          await onComplete(output, {
            type: 'interview_preparation',
            teamExecutionTime: result.executionTimeMs,
          });
        } else {
          await onComplete(
            `é¢è¯•å‡†å¤‡åˆ†æé‡åˆ°é—®é¢˜ï¼š${result.error || 'æœªçŸ¥é”™è¯¯'}ï¼Œè¯·ç¨åé‡è¯•ã€‚`,
            {
              type: 'interview_preparation',
              error: true,
            }
          );
        }
      } catch (error) {
        this.logger.error(
          `Interview preparation failed: ${error instanceof Error ? error.message : String(error)}`
        );
        await onComplete(`é¢è¯•å‡†å¤‡åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚`, {
          type: 'interview_preparation',
          error: true,
        });
      }
    } else {
      await this.handleMockInterview(userId, '', content, onChunk, onComplete);
    }
  }

  private async handleCareerTransition(
    userId: string,
    content: string,
    metadata: Record<string, any> | undefined,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    onChunk({
      type: 'chunk',
      content: 'æ­£åœ¨å¯åŠ¨å¤šæ™ºèƒ½ä½“å›¢é˜Ÿè¿›è¡ŒèŒä¸šè½¬å‹åˆ†æ...\n\n',
      timestamp: Date.now(),
    });

    if (this.useTeamAgents && this.teamTaskService?.isEnabled()) {
      try {
        const resumeData = await this.getUserResumeContent(userId);

        onChunk({
          type: 'chunk',
          content: 'ğŸ”„ æ­£åœ¨åˆ†ææ‚¨çš„æŠ€èƒ½å’Œè½¬å‹è·¯å¾„...\n',
          timestamp: Date.now(),
        });

        const result =
          await this.teamTaskService.executeCareerTransitionAnalysis({
            userId,
            taskType: ComplexTaskType.CAREER_TRANSITION_ANALYSIS,
            resumeContent: resumeData?.content,
            additionalContext: {
              currentField: metadata?.currentField,
              targetField: metadata?.targetField,
            },
          });

        if (result.success && result.data) {
          onChunk({
            type: 'chunk',
            content: '\nâœ… èŒä¸šè½¬å‹åˆ†æå®Œæˆï¼\n\n',
            timestamp: Date.now(),
          });

          const output = this.formatTeamResult(result.data);
          await onComplete(output, {
            type: 'career_transition',
            teamExecutionTime: result.executionTimeMs,
          });
        } else {
          await onComplete(
            `èŒä¸šè½¬å‹åˆ†æé‡åˆ°é—®é¢˜ï¼š${result.error || 'æœªçŸ¥é”™è¯¯'}ï¼Œè¯·ç¨åé‡è¯•ã€‚`,
            {
              type: 'career_transition',
              error: true,
            }
          );
        }
      } catch (error) {
        this.logger.error(
          `Career transition analysis failed: ${error instanceof Error ? error.message : String(error)}`
        );
        await onComplete(`èŒä¸šè½¬å‹åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚`, {
          type: 'career_transition',
          error: true,
        });
      }
    } else {
      await this.handleCareerAdvice(userId, content, onChunk, onComplete);
    }
  }

  private async handleCompetitiveAnalysis(
    userId: string,
    content: string,
    metadata: Record<string, any> | undefined,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    onChunk({
      type: 'chunk',
      content: 'æ­£åœ¨å¯åŠ¨å¤šæ™ºèƒ½ä½“å›¢é˜Ÿè¿›è¡Œç«äº‰åŠ›åˆ†æ...\n\n',
      timestamp: Date.now(),
    });

    if (this.useTeamAgents && this.teamTaskService?.isEnabled()) {
      try {
        const resumeData = await this.getUserResumeContent(userId);
        const jd = metadata?.jobDescription || metadata?.jd;

        if (!resumeData || !jd) {
          await onComplete(
            'ç«äº‰åŠ›åˆ†æéœ€è¦æ‚¨çš„ç®€å†å’Œç›®æ ‡èŒä½æè¿°ï¼Œè¯·ç¡®ä¿å·²ä¸Šä¼ ç®€å†å¹¶æä¾›JDã€‚',
            { type: 'competitive_analysis', requiresData: true }
          );
          return;
        }

        onChunk({
          type: 'chunk',
          content: 'ğŸ“Š æ­£åœ¨åˆ†ææ‚¨çš„ç«äº‰åŠ›...\n',
          timestamp: Date.now(),
        });

        const result = await this.teamTaskService.executeCompetitiveAnalysis({
          userId,
          taskType: ComplexTaskType.COMPETITIVE_ANALYSIS,
          resumeContent: resumeData.content,
          jobDescription: jd,
        });

        if (result.success && result.data) {
          onChunk({
            type: 'chunk',
            content: '\nâœ… ç«äº‰åŠ›åˆ†æå®Œæˆï¼\n\n',
            timestamp: Date.now(),
          });

          const output = this.formatTeamResult(result.data);
          await onComplete(output, {
            type: 'competitive_analysis',
            teamExecutionTime: result.executionTimeMs,
          });
        } else {
          await onComplete(
            `ç«äº‰åŠ›åˆ†æé‡åˆ°é—®é¢˜ï¼š${result.error || 'æœªçŸ¥é”™è¯¯'}ï¼Œè¯·ç¨åé‡è¯•ã€‚`,
            {
              type: 'competitive_analysis',
              error: true,
            }
          );
        }
      } catch (error) {
        this.logger.error(
          `Competitive analysis failed: ${error instanceof Error ? error.message : String(error)}`
        );
        await onComplete(`ç«äº‰åŠ›åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚`, {
          type: 'competitive_analysis',
          error: true,
        });
      }
    } else {
      await this.handleSkillAnalysis(userId, content, onChunk, onComplete);
    }
  }

  private formatTeamResult(data: any): string {
    const parts: string[] = [];

    if (data.analysis) {
      parts.push('## ğŸ“‹ åˆ†æç»“æœ\n');
      if (data.analysis.resumeAnalysis) {
        parts.push('### ç®€å†åˆ†æ');
        parts.push(this.formatAnalysisSection(data.analysis.resumeAnalysis));
      }
      if (data.analysis.jdAnalysis) {
        parts.push('\n### èŒä½åˆ†æ');
        parts.push(this.formatAnalysisSection(data.analysis.jdAnalysis));
      }
    }

    if (data.suggestions) {
      parts.push('\n## ğŸ’¡ ä¼˜åŒ–å»ºè®®\n');
      parts.push(this.formatSuggestions(data.suggestions));
    }

    if (data.validation) {
      parts.push('\n## âœ… è´¨é‡æ£€æŸ¥\n');
      parts.push(this.formatValidation(data.validation));
    }

    if (data.finalOutput && typeof data.finalOutput === 'string') {
      parts.push('\n## ğŸ“ è¯¦ç»†å†…å®¹\n');
      parts.push(data.finalOutput);
    }

    return parts.join('\n');
  }

  private formatAnalysisSection(data: any): string {
    if (typeof data === 'string') return data;
    const lines: string[] = [];
    if (data.skills) {
      lines.push(
        `- **æŠ€èƒ½**: ${Array.isArray(data.skills) ? data.skills.join(', ') : data.skills}`
      );
    }
    if (data.strengths) {
      lines.push(
        `- **ä¼˜åŠ¿**: ${Array.isArray(data.strengths) ? data.strengths.join(', ') : data.strengths}`
      );
    }
    if (data.requiredSkills) {
      lines.push(
        `- **è¦æ±‚æŠ€èƒ½**: ${Array.isArray(data.requiredSkills) ? data.requiredSkills.join(', ') : data.requiredSkills}`
      );
    }
    return lines.join('\n');
  }

  private formatSuggestions(data: any): string {
    if (typeof data === 'string') return data;
    if (Array.isArray(data.suggestions)) {
      return data.suggestions
        .map(
          (s: any, i: number) =>
            `${i + 1}. ${typeof s === 'string' ? s : s.suggestion || s.message || JSON.stringify(s)}`
        )
        .join('\n');
    }
    if (data.improvedContent) {
      return data.improvedContent;
    }
    return JSON.stringify(data, null, 2);
  }

  private formatValidation(data: any): string {
    if (typeof data === 'string') return data;
    const lines: string[] = [];
    if (data.overallScore !== undefined) {
      lines.push(`- **ç»¼åˆè¯„åˆ†**: ${data.overallScore}/100`);
    }
    if (data.isValid !== undefined) {
      lines.push(`- **éªŒè¯ç»“æœ**: ${data.isValid ? 'âœ… é€šè¿‡' : 'âš ï¸ éœ€è¦æ”¹è¿›'}`);
    }
    if (Array.isArray(data.issues) && data.issues.length > 0) {
      lines.push(`- **å‘ç°çš„é—®é¢˜**: ${data.issues.length} ä¸ª`);
    }
    return lines.join('\n');
  }

  private async streamAIResponse(
    userId: string,
    systemPrompt: string,
    userMessage: string,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (finalContent: string) => Promise<void>
  ): Promise<void> {
    const prompt = `${systemPrompt}\n\nç”¨æˆ·æ¶ˆæ¯ï¼š${userMessage}\n\nè¯·ç”¨ä¸­æ–‡å›å¤ï¼š`;

    try {
      const aiRequest: AIRequest = {
        model: '',
        prompt,
        temperature: 0.7,
        maxTokens: 1500,
      };

      let fullContent = '';
      const stream = this.aiEngineService.stream(
        aiRequest,
        userId,
        PromptScenario.RESUME_OPTIMIZATION,
        'zh-CN'
      );

      for await (const chunk of stream) {
        if (chunk.content) {
          fullContent += chunk.content;
          onChunk({
            type: 'chunk',
            content: chunk.content,
            timestamp: Date.now(),
          });
        }
      }

      await onComplete(fullContent);
    } catch (error) {
      this.logger.error(
        `AI streaming failed: ${error instanceof Error ? error.message : String(error)}`
      );
      await onComplete('æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚');
    }
  }

  /**
   * Handle help request
   */
  private async handleHelp(
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    const helpContent = `
## ğŸ¯ æˆ‘å¯ä»¥å¸®æ‚¨åšä»€ä¹ˆï¼Ÿ

### ğŸ“„ ç®€å†ä¼˜åŒ–
- ä¸Šä¼ æ‚¨çš„ç®€å†ï¼Œè¯´"ä¼˜åŒ–ç®€å†"æˆ–"ç®€å†ä¼˜åŒ–"ï¼Œæˆ‘ä¼šå¸®æ‚¨æ¶¦è‰²å†…å®¹ï¼Œæå‡ç«äº‰åŠ›ã€‚

### ğŸ“ˆ é¢è¯•é¢„æµ‹
- åŸºäºæ‚¨çš„èƒŒæ™¯å’Œç›®æ ‡èŒä½ï¼Œé¢„æµ‹é¢è¯•ä¸­å¯èƒ½å‡ºç°çš„é—®é¢˜ï¼Œå¹¶æä¾›æ ¸å¿ƒè€ƒç‚¹åˆ†æã€‚

### ğŸ­ æ¨¡æ‹Ÿé¢è¯•
- è¿›å…¥å®æˆ˜æ¼”ç»ƒï¼Œæˆ‘å°†ä½œä¸ºé¢è¯•å®˜ä¸æ‚¨å¯¹è¯ï¼Œæä¾›å³æ—¶åé¦ˆå’Œæ”¹è¿›å»ºè®®ã€‚

### ğŸ’¼ èŒä½è¾“å…¥
- ç²˜è´´èŒä½æè¿°ï¼ˆJDï¼‰ï¼Œæˆ‘å°†ä¸ºæ‚¨æ·±åº¦è§£ææ ¸å¿ƒéœ€æ±‚ï¼Œå¹¶ç»™å‡ºé’ˆå¯¹æ€§çš„æŠ•é€’å»ºè®®ã€‚

### ğŸ’¡ ä½¿ç”¨æŠ€å·§
1. **ä¸Šä¼ ç®€å†**ï¼šç‚¹å‡»ä¸Šä¼ æŒ‰é’®æˆ–æ‹–æ‹½æ–‡ä»¶å¼€å§‹ã€‚
2. **é€‰æ‹©åŠŸèƒ½**ï¼šç‚¹å‡»æ¬¢è¿å¡ç‰‡ä¸Šçš„åŠŸèƒ½å›¾æ ‡ï¼Œæˆ–ç›´æ¥åœ¨è¾“å…¥æ¡†ä¸­è¯´æ˜æ‚¨çš„éœ€æ±‚ã€‚
3. **æ·±åº¦å¯¹è¯**ï¼šæ‚¨å¯ä»¥å¯¹æˆ‘çš„å›ç­”è¿›è¡Œè¿½é—®ï¼Œè·å–æ›´è¯¦ç»†çš„å»ºè®®ã€‚

æœ‰ä»»ä½•é—®é¢˜ï¼Œéšæ—¶é—®æˆ‘ï¼
`;

    await onComplete(helpContent, { type: 'help' });
  }

  /**
   * Handle general chat with AI
   */
  private async handleGeneralChat(
    userId: string,
    content: string,
    onChunk: (chunk: ChatResponse) => void,
    onComplete: (
      finalContent: string,
      metadata?: Record<string, any>
    ) => Promise<void>
  ): Promise<void> {
    // Check if user has resume context
    const resumeData = await this.getUserResumeContent(userId);

    let systemPrompt =
      'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç®€å†ä¼˜åŒ–åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·æ”¹è¿›ç®€å†å†…å®¹ã€æä¾›æ±‚èŒå»ºè®®ã€‚';

    if (resumeData) {
      systemPrompt += `\n\nç”¨æˆ·å·²ä¸Šä¼ ç®€å†ï¼Œä»¥ä¸‹æ˜¯ç®€å†å†…å®¹æ‘˜è¦ï¼š\n${resumeData.content.substring(0, 500)}...`;
    } else {
      systemPrompt +=
        '\n\nç”¨æˆ·å°šæœªä¸Šä¼ ç®€å†ã€‚å¦‚æœç”¨æˆ·è¯¢é—®ç®€å†ç›¸å…³é—®é¢˜ï¼Œå»ºè®®ä»–ä»¬å…ˆä¸Šä¼ ç®€å†ã€‚';
    }

    const prompt = `${systemPrompt}\n\nç”¨æˆ·æ¶ˆæ¯ï¼š${content}\n\nè¯·ç”¨ä¸­æ–‡å›å¤ï¼š`;

    try {
      const aiRequest: AIRequest = {
        model: '',
        prompt,
        temperature: 0.7,
        maxTokens: 1000,
      };

      let fullContent = '';
      const stream = this.aiEngineService.stream(
        aiRequest,
        userId,
        PromptScenario.RESUME_OPTIMIZATION,
        'zh-CN'
      );

      for await (const chunk of stream) {
        if (chunk.content) {
          fullContent += chunk.content;
          onChunk({
            type: 'chunk',
            content: chunk.content,
            timestamp: Date.now(),
          });
        }
      }

      await onComplete(fullContent, { type: 'general_chat' });
    } catch (error) {
      this.logger.error(
        `General chat failed: ${error instanceof Error ? error.message : String(error)}`
      );

      // Fallback response
      let fallbackResponse = 'æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚';

      if (!resumeData) {
        fallbackResponse =
          'æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„ç®€å†ä¼˜åŒ–åŠ©æ‰‹ã€‚è¯·å…ˆä¸Šä¼ æ‚¨çš„ç®€å†ï¼Œç„¶åæˆ‘å¯ä»¥å¸®æ‚¨ï¼š\n\n1. ğŸ“ ä¼˜åŒ–ç®€å†å†…å®¹\n2. ğŸ’¡ æä¾›æ±‚èŒå»ºè®®\n3. ğŸ¯ åˆ†æç®€å†äº®ç‚¹\n\nè¯·ç‚¹å‡»ä¸Šä¼ æŒ‰é’®å¼€å§‹å§ï¼';
      }

      await onComplete(fallbackResponse, { type: 'fallback' });
    }
  }

  /**
   * Generate optimization tips based on content
   */
  private generateOptimizationTips(content: string): string {
    const sections = [
      { key: 'åŸºæœ¬ä¿¡æ¯', tip: 'âœ… å·²ä¼˜åŒ–åŸºæœ¬ä¿¡æ¯ï¼Œå¢å¼ºäº†ä¸ªäººè”ç³»æ–¹å¼çš„æ’ç‰ˆ' },
      { key: 'ä¸“ä¸šæ€»ç»“', tip: 'âœ… å·²ä¼˜åŒ–ä¸“ä¸šæ€»ç»“ï¼Œæå‡äº†æ ¸å¿ƒç«äº‰åŠ›çš„è¡¨è¾¾' },
      { key: 'å·¥ä½œç»å†', tip: 'âœ… å·²ä¼˜åŒ–å·¥ä½œç»å†ï¼Œå¼ºåŒ–äº†é‡åŒ–æˆæœå’ŒæŠ€æœ¯å…³é”®è¯' },
      { key: 'æ•™è‚²èƒŒæ™¯', tip: 'âœ… å·²ä¼˜åŒ–æ•™è‚²èƒŒæ™¯ï¼Œæ•´ç†äº†å­¦æœ¯æˆå°±å’Œè£èª‰' },
      {
        key: 'é¡¹ç›®ç»éªŒ',
        tip: 'âœ… å·²ä¼˜åŒ–é¡¹ç›®ç»éªŒï¼Œçªå‡ºäº†ä¸ªäººåœ¨é¡¹ç›®ä¸­çš„æ ¸å¿ƒè´¡çŒ®',
      },
      { key: 'æŠ€èƒ½åˆ—è¡¨', tip: 'âœ… å·²ä¼˜åŒ–æŠ€èƒ½åˆ—è¡¨ï¼ŒæŒ‰ä¸“ä¸šç±»åˆ«è¿›è¡Œäº†ç»“æ„åŒ–åˆ†ç±»' },
    ];

    const activeTips: string[] = [];
    sections.forEach((section) => {
      if (content.includes(section.key)) {
        activeTips.push(section.tip);
      }
    });

    if (activeTips.length === 0) return '';

    return (
      '\n\n---\n' +
      activeTips.join('\n') +
      '\n\n**âœ¨ ç®€å†ä¼˜åŒ–å®Œæˆï¼æ‚¨å¯ä»¥ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®æŸ¥çœ‹å¯¹æ¯”æˆ–ä¸‹è½½ç»“æœã€‚**'
    );
  }

  /**
   * Convert parsed resume data to markdown
   */
  private convertParsedDataToMarkdown(parsedData: any): string {
    if (!parsedData) return '';

    const parts: string[] = [];

    // Handle different parsedData formats
    // Some resumes might have markdown field directly
    if (typeof parsedData === 'string') {
      return parsedData;
    }

    if (parsedData.markdown && typeof parsedData.markdown === 'string') {
      return parsedData.markdown;
    }

    if (
      parsedData.extractedText &&
      typeof parsedData.extractedText === 'string'
    ) {
      return parsedData.extractedText;
    }

    // Personal Info
    if (parsedData.personalInfo) {
      const info = parsedData.personalInfo;
      parts.push(`# ${info.name || 'ç®€å†'}\n`);
      if (info.email) parts.push(`ğŸ“§ ${info.email}`);
      if (info.phone) parts.push(`ğŸ“± ${info.phone}`);
      if (info.location) parts.push(`ğŸ“ ${info.location}`);
      parts.push('');
    }

    // Summary
    if (parsedData.summary) {
      parts.push('## ä¸“ä¸šæ€»ç»“\n');
      parts.push(parsedData.summary);
      parts.push('');
    }

    // Experience
    if (parsedData.experience?.length > 0) {
      parts.push('## å·¥ä½œç»å†\n');
      parsedData.experience.forEach((exp: any) => {
        parts.push(`### ${exp.position} @ ${exp.company}`);
        parts.push(`*${exp.startDate} - ${exp.endDate || 'è‡³ä»Š'}*\n`);
        if (exp.description?.length > 0) {
          exp.description.forEach((desc: string) => parts.push(`- ${desc}`));
        }
        parts.push('');
      });
    }

    // Education
    if (parsedData.education?.length > 0) {
      parts.push('## æ•™è‚²èƒŒæ™¯\n');
      parsedData.education.forEach((edu: any) => {
        parts.push(`### ${edu.degree} - ${edu.field}`);
        parts.push(`${edu.institution} | ${edu.startDate} - ${edu.endDate}`);
        parts.push('');
      });
    }

    // Skills
    if (parsedData.skills?.length > 0) {
      parts.push('## æŠ€èƒ½åˆ—è¡¨\n');
      parts.push(parsedData.skills.join('ã€'));
      parts.push('');
    }

    // Projects
    if (parsedData.projects?.length > 0) {
      parts.push('## é¡¹ç›®ç»éªŒ\n');
      parsedData.projects.forEach((proj: any) => {
        parts.push(`### ${proj.name}`);
        parts.push(proj.description);
        if (proj.technologies?.length > 0) {
          parts.push(`**æŠ€æœ¯æ ˆ**: ${proj.technologies.join(', ')}`);
        }
        parts.push('');
      });
    }

    const result = parts.join('\n');

    // If we couldn't extract any content, try to stringify the data
    if (!result || result.trim().length === 0) {
      this.logger.warn(
        'Could not convert parsedData to markdown, using JSON fallback'
      );
      return JSON.stringify(parsedData, null, 2);
    }

    return result;
  }
}
